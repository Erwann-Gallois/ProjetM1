{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e311e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from bdd_script import get_indicateur, get_labels\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780138db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chargement des données ===\n",
    "raw_train = get_indicateur(3)\n",
    "train_df = pd.json_normalize(raw_train)\n",
    "colonnes_a_supprimer = [col for col in train_df.columns if col.startswith(\"has_unit.\") or col.startswith(\"ratio_unit.\")]\n",
    "train_df = train_df.drop(columns=colonnes_a_supprimer, errors='ignore') # Utilisez errors='ignore' pour éviter les erreurs si les colonnes n'existent pas\n",
    "train_df.fillna(train_df.mean(), inplace=True)\n",
    "\n",
    "raw_test = get_indicateur(1)\n",
    "val_df = pd.json_normalize(raw_test).drop(columns=colonnes_a_supprimer, errors='ignore')\n",
    "val_df = val_df.reindex(columns=train_df.columns, fill_value=train_df.mean()) # Utilisez fill_value pour aligner les colonnes et gérer les valeurs manquantes\n",
    "X_train = train_df\n",
    "y_train = get_labels(3)\n",
    "X_val = val_df\n",
    "y_val = get_labels(1)\n",
    "\n",
    "# === Normalisation ===\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "# === Balancement ===\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# === ADASYN ===\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_res_adasyn, y_res_adasyn = adasyn.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e17ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70        39\n",
      "           1       0.27      0.24      0.25        17\n",
      "\n",
      "    accuracy                           0.57        56\n",
      "   macro avg       0.47      0.48      0.47        56\n",
      "weighted avg       0.56      0.57      0.56        56\n",
      "\n",
      "Matrice de confusion :\n",
      "[[28 11]\n",
      " [13  4]]\n",
      "AUC :\n",
      "0.4524886877828054\n",
      "Meilleurs paramètres trouvés : {'C': 2, 'class_weight': None, 'gamma': 0.4, 'kernel': 'sigmoid', 'probability': True}\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(random_state=42)\n",
    "# === Paramètres pour la recherche de grille ===\n",
    "param_grid = {\n",
    "    'C': [i for i in range(1, 10)],\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, \"scale\", \"auto\"],\n",
    "    'kernel': ['linear', 'rbf',\"poly\", 'sigmoid'],\n",
    "    \"probability\": [True, False],\n",
    "    \"class_weight\": [None],\n",
    "}\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "# === Recherche de grille ===\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=5, scoring=scorer, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"AUC :\")\n",
    "print(roc_auc_score(y_val, grid_search.predict_proba(X_val)[:, 1])) # AUC pour le meilleur modèle SVM\n",
    "best_svm = grid_search.best_estimator_\n",
    "print(\"Meilleurs paramètres trouvés :\", grid_search.best_params_) # Afficher les meilleurs parametres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9ba7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madgu\\.conda\\envs\\ProjetM1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 864 is smaller than n_iter=1000. Running 864 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés (RandomizedSearchCV) : {'probability': True, 'kernel': 'sigmoid', 'gamma': 0.1, 'class_weight': 'balanced', 'C': 9}\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(svm_clf, param_grid, n_iter=1000, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_svm_random = random_search.best_estimator_\n",
    "print(\"Meilleurs paramètres trouvés (RandomizedSearchCV) :\", random_search.best_params_) # Afficher les meilleurs parametres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76693165",
   "metadata": {},
   "source": [
    "Non Balancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07625ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70        39\n",
      "           1       0.27      0.24      0.25        17\n",
      "\n",
      "    accuracy                           0.57        56\n",
      "   macro avg       0.47      0.48      0.47        56\n",
      "weighted avg       0.56      0.57      0.56        56\n",
      "\n",
      "Matrice de confusion :\n",
      "[[28 11]\n",
      " [13  4]]\n",
      "AUC :\n",
      "0.4524886877828054\n"
     ]
    }
   ],
   "source": [
    "best_svm.fit(X_train, y_train)\n",
    "y_pred = best_svm.predict(X_val)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"AUC :\")\n",
    "print(roc_auc_score(y_val, best_svm.predict_proba(X_val)[:, 1])) # AUC pour le meilleur modèle SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693de43b",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81afeff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.33      0.45        39\n",
      "           1       0.30      0.65      0.41        17\n",
      "\n",
      "    accuracy                           0.43        56\n",
      "   macro avg       0.49      0.49      0.43        56\n",
      "weighted avg       0.57      0.43      0.44        56\n",
      "\n",
      "Matrice de confusion :\n",
      "[[13 26]\n",
      " [ 6 11]]\n",
      "AUC :\n",
      "0.49924585218702866\n"
     ]
    }
   ],
   "source": [
    "best_svm.fit(X_res, y_res)\n",
    "y_pred = best_svm.predict(X_val)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"AUC :\")\n",
    "print(roc_auc_score(y_val, best_svm.predict_proba(X_val)[:, 1])) # AUC pour le meilleur modèle SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfed14b",
   "metadata": {},
   "source": [
    "ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c9f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.36      0.47        39\n",
      "           1       0.31      0.65      0.42        17\n",
      "\n",
      "    accuracy                           0.45        56\n",
      "   macro avg       0.50      0.50      0.44        56\n",
      "weighted avg       0.58      0.45      0.46        56\n",
      "\n",
      "Matrice de confusion :\n",
      "[[14 25]\n",
      " [ 6 11]]\n",
      "AUC :\n",
      "0.48717948717948717\n"
     ]
    }
   ],
   "source": [
    "best_svm.fit(X_res_adasyn, y_res_adasyn)\n",
    "y_pred = best_svm.predict(X_val)\n",
    "print(\"Classification report :\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"AUC :\")\n",
    "print(roc_auc_score(y_val, best_svm.predict_proba(X_val)[:, 1])) # AUC pour le meilleur modèle SVM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjetM1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
